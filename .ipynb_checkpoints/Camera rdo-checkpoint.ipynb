{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e592d6fb",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c8bfe",
   "metadata": {},
   "source": [
    "Model library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b445f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57174fb4",
   "metadata": {},
   "source": [
    "Cam library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d365b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import opencv for computer vision stuff\n",
    "#import cv2\n",
    "# Import matplotlib so we can visualize an image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d39572",
   "metadata": {},
   "source": [
    "Border and area library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3dd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #kernel problem\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from PIL import Image as im\n",
    "import os\n",
    "import numpy as np#csv\n",
    "from numpy import asarray\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc5d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eb822a",
   "metadata": {},
   "source": [
    "Color table lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143fd00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from math import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d57118",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_number=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc71e499",
   "metadata": {},
   "source": [
    "# Prediction Tests"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4234152b",
   "metadata": {},
   "source": [
    "#Data Image\n",
    "#images\n",
    "apple0 = r'C:\\Users\\tgillard\\Desktop\\internship\\1_Sorted apples\\T3 Granny Smith_trie\\Basics\\0 nothing\\111000.BMP'\n",
    "apple1 = r'C:\\Users\\tgillard\\Desktop\\internship\\1_Sorted apples\\T3 Granny Smith_trie\\Basics\\1stem\\520100.BMP'\n",
    "apple2 = r'C:\\Users\\tgillard\\Desktop\\internship\\1_Sorted apples\\T3 Granny Smith_trie\\Basics\\2calyx\\1302200.BMP'\n",
    "apple3 = r'C:\\Users\\tgillard\\Desktop\\internship\\1_Sorted apples\\T3 Granny Smith_trie\\Basics\\3defect\\819300.BMP'\n",
    "apple_other =r'C:\\Users\\tgillard\\Desktop\\internship\\1_Sorted apples\\T2 Eve_trie\\Basics\\0 nothing\\222000.BMP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4ac7b",
   "metadata": {},
   "source": [
    "Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9619eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(r\"C:\\Users\\thiba\\Desktop\\Test_Model\\last_night-97.71.h5\")\n",
    "class_names = ['0 nothing','1stem','2calyx','3defect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfec3c",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32a96a29",
   "metadata": {},
   "source": [
    "img = tf.keras.utils.load_img(\n",
    "    apple_other, target_size=(108, 108)#\\\\\\\\\\\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a8018b5",
   "metadata": {},
   "source": [
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e45e127b",
   "metadata": {},
   "source": [
    "print(score)\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531be35d",
   "metadata": {},
   "source": [
    "# Camera test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0e8cabe",
   "metadata": {},
   "source": [
    "# Connect to webcam\n",
    "cap = cv2.VideoCapture(device_number)\n",
    "# Loop through every frame until we close our webcam\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Show image \n",
    "    cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    # Checks whether q has been hit and stops the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# Releases the webcam\n",
    "cap.release()\n",
    "# Closes the frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e156c",
   "metadata": {},
   "source": [
    "# Methods & functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d2296",
   "metadata": {},
   "source": [
    "Method to display the results of analysis() in a coloured summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9fa382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Color_Tab(liste):\n",
    "    \n",
    "    n=len(liste)\n",
    "    n=ceil(sqrt(n))\n",
    "\n",
    "    while (True) :\n",
    "        m = 500/n\n",
    "        mm = int(m)\n",
    "        if m-mm==0 :\n",
    "            break\n",
    "        n += 1\n",
    "\n",
    "    #cell size\n",
    "    c = m\n",
    "\n",
    "    # grid size\n",
    "    width = 500\n",
    "    height = int(c*(len(liste)/(width/c))) #cell size * no. of rows\n",
    "    height = int(round((height+25)/50)*50) #rounded up in his superior fifties\n",
    "\n",
    "\n",
    "    #main programme \n",
    "    fen1 = Tk()\n",
    "\n",
    "    can1 = Canvas(fen1, width =width, height =height, bg ='white')\n",
    "    can1.pack(side =TOP, padx =5, pady =5)\n",
    "\n",
    "    v=0\n",
    "    for y in range (int(500/c)) :\n",
    "        for i in range (int(500/c)) : \n",
    "            if i+v < len(liste):\n",
    "                if liste[i+v]==0:    \n",
    "                    can1.create_rectangle(i*c, (y)*c, i*c+c, (y)*c+c, fill='#0f1')\n",
    "                elif liste[i+v]==1:\n",
    "                    can1.create_rectangle(i*c, (y)*c, i*c+c, (y)*c+c, fill='blue')\n",
    "                elif liste[i+v]==2:\n",
    "                    can1.create_rectangle(i*c, (y)*c, i*c+c, (y)*c+c, fill='#f5f')\n",
    "                elif liste[i+v]==3:\n",
    "                    can1.create_rectangle(i*c, (y)*c, i*c+c, (y)*c+c, fill='red')\n",
    "        v=v+i+1\n",
    "\n",
    "    fen1.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671d686",
   "metadata": {},
   "source": [
    "# -- Basic Cam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a23151",
   "metadata": {},
   "source": [
    "Methods to record a live photo : take_photo() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36bc869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_photo_show(): \n",
    "    cap = cv2.VideoCapture(device_number)\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        #cv2.imwrite('webcamphoto.jpg', frame)\n",
    "        #cv2.imshow('Cam Video', frame)\n",
    "        #cap.release()\n",
    "        # creating image object of\n",
    "        # above array\n",
    "        \n",
    "        # You may need to convert the color.\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        im1 = im.fromarray(frame, 'RGB')\n",
    "        \n",
    "        # Shows the image in image viewer\n",
    "        im1.show()\n",
    "    else :\n",
    "        print('cap not open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf4a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_photo(): \n",
    "    a = True\n",
    "    cap = cv2.VideoCapture(device_number)\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        #cv2.imwrite('webcamphoto.jpg', frame)\n",
    "        cap.release()\n",
    "        return a, frame\n",
    "    else :\n",
    "        print('cap not open')\n",
    "        a = False\n",
    "        b = 0\n",
    "        return a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a24bc6",
   "metadata": {},
   "source": [
    "Camera test Method, rendering in real time : show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1749e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video():\n",
    "    # Connect to webcam\n",
    "    cap = cv2.VideoCapture(device_number)\n",
    "    # Loop through every frame until we close our webcam\n",
    "    while cap.isOpened(): \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Show image \n",
    "        # Creating line\n",
    "        cv2.line(frame, (20, 160), (100, 160), (0, 0, 255), 10)\n",
    "        cv2.imshow('Cam Video', frame)\n",
    "\n",
    "        # Checks whether q has been hit and stops the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "\n",
    "    # Releases the webcam\n",
    "    cap.release()\n",
    "    # Closes the frame\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959c6d7",
   "metadata": {},
   "source": [
    "# -- Border and Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e0783",
   "metadata": {},
   "source": [
    "A first function find_boarder(apple_image) takes in a picture of an apple to find and return the north-south-east and west edges of it.\n",
    "\n",
    "The method display(image) also takes in an apple picture and displays the apple with the traces of the edges, the contour, the circle with \n",
    "D/2 and the corresponding square. The purpose of this function is to visualise the areas of interest and check the accuracy of the methods used.\n",
    "\n",
    "The crop(image) function takes an input image and returns its crop version, whose crop points are defined by the find_boarder() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "916992e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boarder(apple_image):\n",
    "    #NS--- Luminosite\n",
    "    #Find North boarder\n",
    "    n=0\n",
    "    s=0\n",
    "    e=0\n",
    "    w=0\n",
    "    for i in range(15,190):\n",
    "        r,v,b=apple_image.getpixel((320,i))\n",
    "        #print(r,v,b)\n",
    "        lumi=r+v+b\n",
    "        if lumi > 150:\n",
    "            n=i\n",
    "            break \n",
    "    #print(n)\n",
    "\n",
    "    #Find South boarder\n",
    "    for i in range(455, 300, -1):\n",
    "        r,v,b=apple_image.getpixel((320,i))\n",
    "        lumi=r+v+b\n",
    "        if lumi > 150:\n",
    "            s=i\n",
    "            break \n",
    "    #print(s)\n",
    "\n",
    "    #EW--- presence de bleu\n",
    "    #Find East boarder\n",
    "    for i in range(20, 253):\n",
    "        r,v,b=apple_image.getpixel((i,240))\n",
    "        lumi=r+v+b\n",
    "        if lumi > 210:\n",
    "            e=i\n",
    "            break \n",
    "    #print(e)\n",
    "    #Find West boarder\n",
    "    for i in range(620, 380, -1):\n",
    "        r,v,b=apple_image.getpixel((i,240))\n",
    "        lumi=r+v+b\n",
    "        if lumi > 210:\n",
    "            w=i\n",
    "            break\n",
    "    #print(w)\n",
    "\n",
    "    return n, s, e, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b54219d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage(image):\n",
    "    #im = Image.open(image)\n",
    "    im = image\n",
    "    \n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(im)\n",
    "\n",
    "    #Big Rect -----\n",
    "    n, s, e, w = find_boarder(im)\n",
    "    print(n, s, e, w,)\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((w, n), e-w, s-n, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    #Area\n",
    "    Apple_Diameter=((s-n)+(w-e))/2\n",
    "    #circ = patches.Circle(((w-e)/2,(s-n)/2),Apple_Diameter/2, linewidth=1, edgecolor='b', facecolor='none')\n",
    "    circ = patches.Circle((e+(w-e)/2,n+(s-n)/2),Apple_Diameter/2, linewidth=1, edgecolor='b', facecolor='none')\n",
    "    ax.add_patch(circ)\n",
    "\n",
    "    #circle 50% Area\n",
    "    Apple_Diameter=((s-n)+(w-e))/2\n",
    "    #circ = patches.Circle(((w-e)/2,(s-n)/2),Apple_Diameter/2, linewidth=1, edgecolor='b', facecolor='none')\n",
    "    small_circ = patches.Circle((e+(w-e)/2,n+(s-n)/2),Apple_Diameter/4, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(small_circ)\n",
    "\n",
    "    #rectangle 50% Area\n",
    "    small_rect = patches.Rectangle(((-(Apple_Diameter/4)+e+(w-e)/2, n+(s-n)/4)), Apple_Diameter/2, Apple_Diameter/2, linewidth=1, edgecolor='b', facecolor='none')\n",
    "    ax.add_patch(small_rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d38b1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_border(frame):\n",
    "    \n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    ima = im.fromarray(image, 'RGB')#numpy.array to an image\n",
    "    \n",
    "    #Big Rect -----\n",
    "    n, s, e, w = find_boarder(ima)\n",
    "    Apple_Diameter=((s-n)+(w-e))/2\n",
    "    centre_x=e+(w-e)/2\n",
    "    centre_y=n+(s-n)/2\n",
    "    \n",
    "    little_Diameter = 4\n",
    "    # Setting the points for cropped image\n",
    "    left = int(centre_x-Apple_Diameter/little_Diameter)\n",
    "    top = int(centre_y-Apple_Diameter/little_Diameter)\n",
    "    right = int(centre_x+Apple_Diameter/little_Diameter)\n",
    "    bottom = int(centre_y+Apple_Diameter/little_Diameter)\n",
    "    \n",
    "   \n",
    "    # Create a Rectangle patch\n",
    "    cv2.rectangle(frame, (w, n), (e, s), (255, 0, 0), 2)\n",
    "\n",
    "    #rectangle 50% Area\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 1), 2)\n",
    "    #small_rect = patches.Rectangle(((-(Apple_Diameter/4)+e+(w-e)/2, n+(s-n)/4)), Apple_Diameter/2, Apple_Diameter/2, linewidth=1, edgecolor='b', facecolor='none')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ecf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image):\n",
    "\n",
    "    #im = Image.open(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    ima = im.fromarray(image, 'RGB')#numpy.array to an image\n",
    "    \n",
    "    n, s, e, w = find_boarder(ima)\n",
    "    Apple_Diameter=((s-n)+(w-e))/2\n",
    "    centre_x=e+(w-e)/2\n",
    "    centre_y=n+(s-n)/2\n",
    "    \n",
    "    # Size of the image in pixels (size of original image)\n",
    "    width, height = ima.size\n",
    "    \n",
    "    little_Diameter = 4\n",
    "    # Setting the points for cropped image\n",
    "    left = centre_x-Apple_Diameter/little_Diameter\n",
    "    top = centre_y-Apple_Diameter/little_Diameter\n",
    "    right = centre_x+Apple_Diameter/little_Diameter\n",
    "    bottom = centre_y+Apple_Diameter/little_Diameter\n",
    "    \n",
    "    # Cropped image of above dimension\n",
    "    # (It will not change original image)\n",
    "    im1 = ima.crop((left, top, right, bottom))\n",
    "    \n",
    "    # Shows the image in image viewer\n",
    "    #im1.show()\n",
    "    # PIL images into NumPy arrays\n",
    "    im1 = asarray(im1)\n",
    "    \n",
    "    return im1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851245d4",
   "metadata": {},
   "source": [
    "# -- Test Camera img Border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "733424c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_crop_video():\n",
    "    # Connect to webcam\n",
    "    cap = cv2.VideoCapture(device_number)\n",
    "    # Loop through every frame until we close our webcam\n",
    "    while cap.isOpened(): \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Show the crop image\n",
    "        image = frame\n",
    "        crop_image=crop(image)\n",
    "        \n",
    "        cv2.imshow('Crop video', crop_image)\n",
    "        \n",
    "        # Checks whether q has been hit and stops the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "\n",
    "    # Releases the webcam\n",
    "    cap.release()\n",
    "    # Closes the frame\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d469f",
   "metadata": {},
   "source": [
    "# -- Main Method, apple analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2e36b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apple_analyse():\n",
    "    results_list = []\n",
    "    # Connect to webcam\n",
    "    cap = cv2.VideoCapture(device_number)\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE, -10)\n",
    "    # Loop through every frame until we close our webcam\n",
    "    last_class = '0 nothing'\n",
    "    \n",
    "    while cap.isOpened(): \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Show the crop image\n",
    "        image = frame\n",
    "        crop_image=crop(image)#return a numpy.array v\n",
    "        \n",
    "        image_to_analysed = im.fromarray(crop_image, 'RGB')\n",
    "        \n",
    "        #resize\n",
    "        image_to_analysed = image_to_analysed.resize((93, 93))\n",
    "        \n",
    "        # Create a batch\n",
    "        img_array = tf.keras.utils.img_to_array(image_to_analysed)\n",
    "        img_array = tf.expand_dims(img_array, 0) \n",
    "        \n",
    "        # Prediction\n",
    "        predictions = model.predict(img_array)\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "        \n",
    "        # Print prediction\n",
    "        #print(score)\n",
    "        #print(\n",
    "        #    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        #    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "        #)\n",
    "        \n",
    "        #show the result in video\n",
    "        #green = 0 nothing, blue = 1 stem, purple = 2 calyx, red = 3 defect\n",
    "\n",
    "        top_class = class_names[np.argmax(score)]\n",
    "        if top_class == last_class :\n",
    "            if top_class == '0 nothing':\n",
    "                cv2.rectangle(frame, (5, 5), (630, 470), (0, 255, 0), 10)\n",
    "                results_list.append(0)# Save the results\n",
    "            elif top_class == '1stem':\n",
    "                cv2.rectangle(frame, (5, 5), (630, 470), (255, 0, 0), 10)\n",
    "                results_list.append(1)# Save the results\n",
    "            elif top_class == '2calyx':\n",
    "                cv2.rectangle(frame, (5, 5), (630, 470), (238, 130, 238), 10)\n",
    "                results_list.append(2)# Save the results\n",
    "            elif top_class == '3defect':\n",
    "                cv2.rectangle(frame, (5, 5), (630, 470), (0, 0, 255), 10)\n",
    "                results_list.append(3)# Save the results\n",
    "        else :\n",
    "            cv2.rectangle(frame, (5, 5), (630, 470), (0, 0, 0), 10)\n",
    "            \n",
    "        last_class = class_names[np.argmax(score)]\n",
    "        \n",
    "        #show the borders\n",
    "        opencv_border(frame)\n",
    "            \n",
    "        cv2.imshow('Cam Video', frame)\n",
    "    \n",
    "        # Checks whether q has been hit and stops the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "    # Releases the webcam\n",
    "    cap.release()\n",
    "    # Closes the frame\n",
    "    cv2.destroyAllWindows()\n",
    "    # Show the results\n",
    "    #print (results_list)\n",
    "    Color_Tab(results_list)\n",
    "    print(len(results_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2e6533",
   "metadata": {},
   "source": [
    "# Menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98dd4cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -- Option 1, Test video simple de la camera\n",
      "2 -- Option 2, Test video Bordure de l image\n",
      "3 -- Option 3, Test video de l image crop\n",
      "4 -- Option 4, analyse\n",
      "5 -- Option 5, Take photo\n",
      "6 -- Exit\n",
      "Enter your choice: 4\n",
      "Handle option 'Option 4'\n",
      "press -q- to quit\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 1s 706ms/step\n",
      "1/1 [==============================] - 1s 756ms/step\n",
      "1/1 [==============================] - 1s 766ms/step\n",
      "1/1 [==============================] - 1s 813ms/step\n",
      "1/1 [==============================] - 1s 804ms/step\n",
      "1/1 [==============================] - 1s 801ms/step\n",
      "1/1 [==============================] - 1s 804ms/step\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 828ms/step\n",
      "1/1 [==============================] - 1s 841ms/step\n",
      "1/1 [==============================] - 1s 876ms/step\n",
      "1/1 [==============================] - 1s 869ms/step\n",
      "1/1 [==============================] - 1s 838ms/step\n",
      "1/1 [==============================] - 1s 823ms/step\n",
      "1/1 [==============================] - 1s 814ms/step\n",
      "1/1 [==============================] - 1s 833ms/step\n",
      "1/1 [==============================] - 1s 852ms/step\n",
      "1/1 [==============================] - 1s 812ms/step\n",
      "1/1 [==============================] - 1s 815ms/step\n",
      "1/1 [==============================] - 1s 819ms/step\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 830ms/step\n",
      "1/1 [==============================] - 1s 820ms/step\n",
      "1/1 [==============================] - 1s 828ms/step\n",
      "1/1 [==============================] - 1s 863ms/step\n",
      "1/1 [==============================] - 1s 815ms/step\n",
      "1/1 [==============================] - 1s 803ms/step\n",
      "1/1 [==============================] - 1s 810ms/step\n",
      "1/1 [==============================] - 1s 812ms/step\n",
      "1/1 [==============================] - 1s 815ms/step\n",
      "1/1 [==============================] - 1s 812ms/step\n",
      "1/1 [==============================] - 1s 807ms/step\n",
      "1/1 [==============================] - 1s 812ms/step\n",
      "1/1 [==============================] - 1s 811ms/step\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 820ms/step\n",
      "1/1 [==============================] - 1s 827ms/step\n",
      "1/1 [==============================] - 1s 844ms/step\n",
      "1/1 [==============================] - 1s 818ms/step\n",
      "1/1 [==============================] - 1s 790ms/step\n",
      "1/1 [==============================] - 1s 837ms/step\n",
      "1/1 [==============================] - 1s 824ms/step\n",
      "1/1 [==============================] - 1s 825ms/step\n",
      "1/1 [==============================] - 1s 810ms/step\n",
      "1/1 [==============================] - 1s 813ms/step\n",
      "1/1 [==============================] - 1s 831ms/step\n",
      "1/1 [==============================] - 1s 874ms/step\n",
      "1/1 [==============================] - 1s 940ms/step\n",
      "1/1 [==============================] - 1s 944ms/step\n",
      "1/1 [==============================] - 1s 812ms/step\n",
      "1/1 [==============================] - 1s 834ms/step\n",
      "1/1 [==============================] - 1s 801ms/step\n",
      "1/1 [==============================] - 1s 822ms/step\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 774ms/step\n",
      "1/1 [==============================] - 1s 865ms/step\n",
      "1/1 [==============================] - 1s 841ms/step\n",
      "151\n",
      "1 -- Option 1, Test video simple de la camera\n",
      "2 -- Option 2, Test video Bordure de l image\n",
      "3 -- Option 3, Test video de l image crop\n",
      "4 -- Option 4, analyse\n",
      "5 -- Option 5, Take photo\n",
      "6 -- Exit\n",
      "Enter your choice: 6\n",
      "Thanks\n"
     ]
    }
   ],
   "source": [
    "menu_options = {\n",
    "    1: 'Option 1, Test video simple de la camera',\n",
    "    2: 'Option 2, Test video Bordure de l image',\n",
    "    3: 'Option 3, Test video de l image crop',\n",
    "    4: 'Option 4, analyse',\n",
    "    5: 'Option 5, Take photo',\n",
    "    6: 'Exit',\n",
    "}\n",
    "\n",
    "def print_menu():\n",
    "    for key in menu_options.keys():\n",
    "        print (key, '--', menu_options[key] )\n",
    "\n",
    "def option1():\n",
    "    print('Handle option \\'Option 1\\'')\n",
    "    print('press -q- to quit')\n",
    "    show_video()\n",
    "\n",
    "def option2():\n",
    "    print('Handle option \\'Option 2\\'')\n",
    "    choice = int(input(\"Choose an image between 0 and 4 :\"))\n",
    "    if choice == 0:\n",
    "        affichage(apple0)\n",
    "    elif choice == 1:\n",
    "        affichage(apple1)\n",
    "    elif choice == 2:\n",
    "        affichage(apple2)\n",
    "    elif choice == 3:\n",
    "        affichage(apple3)\n",
    "    elif choice == 4:\n",
    "        affichage(apple_other)\n",
    "    else:\n",
    "        print('Invalid option. Please enter a number between 0 and 4')\n",
    "\n",
    "def option3():\n",
    "    print('Handle option \\'Option 3\\'')\n",
    "    print('press -q- to quit')\n",
    "    cam_crop_video()\n",
    "    \n",
    "def option4():\n",
    "    print('Handle option \\'Option 4\\'')\n",
    "    print('press -q- to quit')\n",
    "    apple_analyse()\n",
    "\n",
    "def option5():\n",
    "    print('Handle option \\'Option 5\\'')\n",
    "    print('0 = simple pic','/n','1 = pic with border line/n','2 = crop pic/n')\n",
    "    choice = int(input('Choose an image between 0 and 2 :'))\n",
    "    if choice == 0:\n",
    "        take_photo_show()\n",
    "    elif choice == 1:\n",
    "        check, imgage_pic = take_photo()\n",
    "        if check:\n",
    "            affichage(imgage_pic)\n",
    "    elif choice == 2:\n",
    "        check, imgage_pic = take_photo()\n",
    "        if check:\n",
    "            crop(imgage_pic)\n",
    "    else:\n",
    "        print('Invalid option. Please enter a number between 0 and 2')\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    while(True):\n",
    "        print_menu()\n",
    "        option = ''\n",
    "        try:\n",
    "            option = int(input('Enter your choice: '))\n",
    "        except:\n",
    "            print('Wrong input. Please enter a number ...')\n",
    "        #Check what choice was entered and act accordingly\n",
    "        if option == 1:\n",
    "            option1()\n",
    "        elif option == 2:\n",
    "            option2()\n",
    "        elif option == 3:\n",
    "            option3()\n",
    "        elif option == 4:\n",
    "            option4()\n",
    "        elif option == 5:\n",
    "            option5()\n",
    "        elif option == 6:\n",
    "            print('Thanks')\n",
    "            break\n",
    "            exit()\n",
    "        else:\n",
    "            print('Invalid option. Please enter a number between 1 and 5.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200801f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
